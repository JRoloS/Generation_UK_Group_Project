{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Pandas Functions\n",
    "\n",
    "Please run the imports first and keep in mind that some blocks require an absolute path csv and a DF loaded to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd                                                                                 # Loads Pandas package\n",
    "import os                                                                                           # For OS related paths "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ABSOLUTE PATH FOR RAW DATA   \n",
    "\n",
    "##### Takes: raw_data_name that should be the name of one of the csv's files \n",
    "##### Returns: a variable named csv containing the absolute path to the raw_data subfolder folder plus the name of the file in raw_data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ABSOLUTE PATH FOR RAW DATA   \n",
    "\n",
    "def absolute_path_for_raw_data(raw_data_file):\n",
    "    abspath = os.path.abspath(\"../raw_data\")\n",
    "    csv = abspath + \"\\\\\" + raw_data_file\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jzzz\\Python\\final-project\\brewed-awakening-final-project\\raw_data\\leeds_01-01-2020_09-00-00.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. [TEST RUN] ABSOLUTE PATH FOR RAW DATA\n",
    "\n",
    "# Current Files are Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "csv = absolute_path_for_raw_data(raw_data_file)\n",
    "print(csv) # Prints the newly formed absolute path with the raw_data_file name given.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #LOADS (EXTRACT) DATAFRAME\n",
    "\n",
    "#### Loads the df with headers .... just put outside any function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADS (EXTRACT) DATAFRAME\n",
    "columns = ['date_time', 'Location', 'full_name', 'order', 'amount', 'payment_type', 'card_number']  # Headers for the orders csv files\n",
    "df = pd.read_csv(csv, header=None, names=columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SANITISE CSV (Remove given Columns) \n",
    "\n",
    "#### Takes: csv(absolute path to filename), and a list of columns to be dropped on a variable called sanatise_these_columns\n",
    "#### Returns: the sanitised dataframe as df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SANITISE CSV (Remove given Columns) \n",
    "\n",
    "def sanitise_csv(csv,sanitise_these_columns):\n",
    "    try:\n",
    "        sanatisedf = df.drop(columns=sanitise_these_columns)\n",
    "    except FileNotFoundError as fnfe:\n",
    "        print(f'File not found: {fnfe}')\n",
    "\n",
    "    return sanatisedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>Location</th>\n",
       "      <th>order</th>\n",
       "      <th>amount</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2020 09:00</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Regular Chai latte - 2.30, Regular Speciality ...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>CASH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2020 09:01</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Large Chai latte - 2.60, Regular Filter coffee...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>CARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2020 09:03</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Large Speciality Tea - English breakfast - 1.6...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>CARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2020 09:04</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Large Chai latte - 2.60, Large Iced americano ...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>CARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2020 09:06</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Regular Hot Chocolate - 1.40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>CARD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_time Location   \n",
       "0  01/01/2020 09:00    Leeds  \\\n",
       "1  01/01/2020 09:01    Leeds   \n",
       "2  01/01/2020 09:03    Leeds   \n",
       "3  01/01/2020 09:04    Leeds   \n",
       "4  01/01/2020 09:06    Leeds   \n",
       "\n",
       "                                               order  amount payment_type  \n",
       "0  Regular Chai latte - 2.30, Regular Speciality ...     3.6         CASH  \n",
       "1  Large Chai latte - 2.60, Regular Filter coffee...     4.1         CARD  \n",
       "2  Large Speciality Tea - English breakfast - 1.6...     2.9         CARD  \n",
       "3  Large Chai latte - 2.60, Large Iced americano ...     7.6         CARD  \n",
       "4                       Regular Hot Chocolate - 1.40     1.4         CARD  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. [TEST RUN] SANITISE CSV \n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "columns = ['date_time', 'Location', 'full_name', 'order', 'amount', 'payment_type', 'card_number']  # Headers for the orders csv files\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file)  # returns csv variable with the absolute path\n",
    " \n",
    "sanitise_these_columns = ['full_name', 'card_number']\n",
    "\n",
    "result = sanitise_csv(csv,sanitise_these_columns)\n",
    "result.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. FILTER BY COLUMN VALUE \n",
    "\n",
    "#### Takes: csv(absolute path to filename), column variable with the column header id, value to check\n",
    "#### Returns: the rows in which a column contains a given value AS contain_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FILTER BY COLUMN VALUE \n",
    "\n",
    "def filter_by_column_value(csv,column,value):\n",
    "    try:\n",
    "        contain_values = df[df[column].str.contains(value.upper())]\n",
    "    except FileNotFoundError as fnfe:\n",
    "        print(f'File not found: {fnfe}')\n",
    "\n",
    "    return contain_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>Location</th>\n",
       "      <th>full_name</th>\n",
       "      <th>order</th>\n",
       "      <th>amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>card_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2020 09:01</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Matthew Palmer</td>\n",
       "      <td>Large Chai latte - 2.60, Regular Filter coffee...</td>\n",
       "      <td>4.10</td>\n",
       "      <td>CARD</td>\n",
       "      <td>5.933193e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2020 09:03</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Mack Cendejas</td>\n",
       "      <td>Large Speciality Tea - English breakfast - 1.6...</td>\n",
       "      <td>2.90</td>\n",
       "      <td>CARD</td>\n",
       "      <td>2.728143e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2020 09:04</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Thomas Williams</td>\n",
       "      <td>Large Chai latte - 2.60, Large Iced americano ...</td>\n",
       "      <td>7.60</td>\n",
       "      <td>CARD</td>\n",
       "      <td>2.992561e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2020 09:06</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Diane Ferree</td>\n",
       "      <td>Regular Hot Chocolate - 1.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>CARD</td>\n",
       "      <td>8.040887e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/01/2020 09:08</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Bruce Watts</td>\n",
       "      <td>Regular Chai latte - 2.30, Regular Filter coff...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>CARD</td>\n",
       "      <td>2.242609e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01/01/2020 09:09</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Sergio Vanmeter</td>\n",
       "      <td>Regular Iced americano - 2.15, Regular Hot Cho...</td>\n",
       "      <td>10.75</td>\n",
       "      <td>CARD</td>\n",
       "      <td>1.548663e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01/01/2020 09:11</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Rosemary Wertman</td>\n",
       "      <td>Regular Filter coffee - 1.50, Regular Hot Choc...</td>\n",
       "      <td>8.40</td>\n",
       "      <td>CARD</td>\n",
       "      <td>6.706720e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01/01/2020 09:12</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Marcia Mason</td>\n",
       "      <td>Large Iced americano - 2.50, Regular Chai latt...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>CARD</td>\n",
       "      <td>2.590703e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01/01/2020 09:19</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Richard Redding</td>\n",
       "      <td>Regular Hot Chocolate - 1.40, Large Filter cof...</td>\n",
       "      <td>6.85</td>\n",
       "      <td>CARD</td>\n",
       "      <td>4.480989e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01/01/2020 09:21</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Jean Wontor</td>\n",
       "      <td>Large Speciality Tea - English breakfast - 1.6...</td>\n",
       "      <td>4.10</td>\n",
       "      <td>CARD</td>\n",
       "      <td>3.200300e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date_time Location         full_name   \n",
       "1   01/01/2020 09:01    Leeds    Matthew Palmer  \\\n",
       "2   01/01/2020 09:03    Leeds     Mack Cendejas   \n",
       "3   01/01/2020 09:04    Leeds   Thomas Williams   \n",
       "4   01/01/2020 09:06    Leeds      Diane Ferree   \n",
       "5   01/01/2020 09:08    Leeds       Bruce Watts   \n",
       "6   01/01/2020 09:09    Leeds   Sergio Vanmeter   \n",
       "7   01/01/2020 09:11    Leeds  Rosemary Wertman   \n",
       "8   01/01/2020 09:12    Leeds      Marcia Mason   \n",
       "12  01/01/2020 09:19    Leeds   Richard Redding   \n",
       "13  01/01/2020 09:21    Leeds       Jean Wontor   \n",
       "\n",
       "                                                order  amount payment_type   \n",
       "1   Large Chai latte - 2.60, Regular Filter coffee...    4.10         CARD  \\\n",
       "2   Large Speciality Tea - English breakfast - 1.6...    2.90         CARD   \n",
       "3   Large Chai latte - 2.60, Large Iced americano ...    7.60         CARD   \n",
       "4                        Regular Hot Chocolate - 1.40    1.40         CARD   \n",
       "5   Regular Chai latte - 2.30, Regular Filter coff...    3.80         CARD   \n",
       "6   Regular Iced americano - 2.15, Regular Hot Cho...   10.75         CARD   \n",
       "7   Regular Filter coffee - 1.50, Regular Hot Choc...    8.40         CARD   \n",
       "8   Large Iced americano - 2.50, Regular Chai latt...    4.80         CARD   \n",
       "12  Regular Hot Chocolate - 1.40, Large Filter cof...    6.85         CARD   \n",
       "13  Large Speciality Tea - English breakfast - 1.6...    4.10         CARD   \n",
       "\n",
       "     card_number  \n",
       "1   5.933193e+15  \n",
       "2   2.728143e+15  \n",
       "3   2.992561e+15  \n",
       "4   8.040887e+15  \n",
       "5   2.242609e+15  \n",
       "6   1.548663e+15  \n",
       "7   6.706720e+15  \n",
       "8   2.590703e+15  \n",
       "12  4.480989e+15  \n",
       "13  3.200300e+15  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. [TEST RUN] FILTER BY COLUMN VALUE\n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "# raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "column = \"payment_type\"  \n",
    "value = \"card\"\n",
    "\n",
    "contain_values = filter_by_column_value(csv,column,value)\n",
    "contain_values.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. COUNT NUMBER OF DIFFERENT VALUES IN COLUMN \n",
    "\n",
    "#### Takes: csv(absolute path to filename), column variable with the column header id,\n",
    "#### Returns: the count of the different values contained in a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. COUNT NUMBER OF DIFFERENT VALUES IN COLUMN \n",
    "\n",
    "def count_number_of_different_values(csv,column):\n",
    "    try:\n",
    "        count = df[column].value_counts(ascending=True)\n",
    "    except FileNotFoundError as fnfe:\n",
    "         print(f'File not found: {fnfe}')\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. [TEST RUN] COUNT NUMBER OF DIFFERENT VALUES IN COLUMN \n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file) # returns csv variable with the absolut path\n",
    "\n",
    "column = \"payment_type\" \n",
    "\n",
    "result = count_number_of_different_values(csv,column)\n",
    "print(str(result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. COUNT NUMBER OF TIMES A VALUE IS REPEATED\n",
    "# \n",
    "#### Takes: csv(absolute path to filename), column variable with the column header id, value to check\n",
    "#### Retuns: the count of the number of times a single value is repeated on a given column AS count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. COUNT NUMBER OF TIMES A VALUE IS REPEATED\n",
    "\n",
    "def count_number_of_times_a_value_is_repeated(csv,column,value):\n",
    "    try:\n",
    "        df = pd.read_csv(csv, header=None, names=columns)\n",
    "        count = df[column].value_counts()[value]\n",
    "    except FileNotFoundError as fnfe:\n",
    "         return f'File not found: {fnfe}'\n",
    "         \n",
    "    except KeyError  as kerr:\n",
    "         return f'No ocurrences of {value} in {column}' \n",
    "        \n",
    "    return f\"the value: {value} was found {str(count)} times.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value: CASH was found 107 times.\n"
     ]
    }
   ],
   "source": [
    "# 5. [TEST RUN] COUNT NUMBER OF TIMES A VALUE IS REPEATED\n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file) # returns csv variable with the absolut path\n",
    "\n",
    "column = \"payment_type\"\n",
    "value = \"CASH\" \n",
    "\n",
    "result = count_number_of_times_a_value_is_repeated(csv,column,value)\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. SAVE DATA FRAME TO FILE AS CSV\n",
    "\n",
    "#### Takes: path for the desired save path, newfile for the desired new file name (.csv extension added at runtime)\n",
    "#### Retuns: a csv file saved to the desired location that contains the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. SAVE DATA FRAME TO FILE AS CSV\n",
    "\n",
    "def save_df_to_csv(path,newfile):\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)  \n",
    "        df.to_csv(path + newfile +\".csv\", header=False)\n",
    "\n",
    "    except:\n",
    "        print(f'Saving operation could not be completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. [TEST RUN] SAVE DATA FRAME TO FILE AS CSV\n",
    "path = \"results/\" # to add folder/subfolder/ if needed\n",
    "newfile = \"newfile\"\n",
    "\n",
    "save_df_to_csv(path,newfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. SAVE DATAFRAME TO FILE AS JSON\n",
    "\n",
    "#### Takes: path for the desired save path, newfile for the desired new file name (.json extension added at runtime)\n",
    "#### Retuns: a csv file saved to the desired location that contains the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. SAVE DATAFRAME TO FILE AS JSON\n",
    "\n",
    "def save_df_to_json(path,newfile):\n",
    "    try:\n",
    "        with open(path + newfile +\".json\", 'w') as f:\n",
    "            f.write(df.to_json(orient='records', lines=True))  # add compression='gzip' to get a zip file (and change newfile extension)\n",
    "\n",
    "    except:\n",
    "        print(f'Saving operation could not be completed')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. [TEST RUN] SAVE DATAFRAME TO FILE AS JSON\n",
    "\n",
    "path = \"results/\" # to add folder/subfolder/ if needed\n",
    "newfile = \"newfile\"\n",
    "\n",
    "save_df_to_json(path,newfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET UNIQUE PRODUCTS IN ORDERS\n",
    "#### Returns a list with the number of  ocurrences for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GET UNIQUE PRODUCTS IN ORDERS\n",
    "\n",
    "def get_unique_products_in_orders():\n",
    "    orders = df['order'].str.split(',', expand = True)\n",
    "    \n",
    "    try:\n",
    "       for item in orders:\n",
    "            result = orders[item].drop_duplicates()\n",
    "       return result \n",
    "    \n",
    "    except:\n",
    "        print(\"Operation could not be completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   None\n",
       "50                         Regular Iced americano - 2.15\n",
       "55                               Large Chai latte - 2.60\n",
       "57      Regular Speciality Tea - English breakfast - ...\n",
       "122      Large Speciality Tea - English breakfast - 1.60\n",
       "142                          Large Iced americano - 2.50\n",
       "154                            Regular Chai latte - 2.30\n",
       "237                         Regular Filter coffee - 1.50\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [TEST RUN] GET UNIQUE PRODUCTS IN ORDERS\n",
    "\n",
    "\n",
    "# The Current Raw csv Files are: Chesterfield or Leeds (comment one out)\n",
    "raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "# raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file)                                                           # Returns a variable called csv with the absolut path for the raw_data_file name [Run this block if fails]\n",
    "columns = ['date_time', 'Location', 'full_name', 'order', 'amount', 'payment_type', 'card_number']  # Headers for the DF\n",
    "df = pd.read_csv(csv, header=None, names=columns)                                                   # Creates the DF\n",
    "\n",
    "result = \"\"\n",
    "\n",
    "\n",
    "result = get_unique_products_in_orders()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Hot Chocolate \n",
      "Price:  1.70\n",
      " Regular Hot Chocolate \n",
      "Price:  1.40\n",
      " Large Chai latte \n",
      "Price:  2.60\n",
      " Regular Chai latte \n",
      "Price:  2.30\n",
      " Regular Speciality Tea - English breakfast \n",
      "Price:  1.30\n"
     ]
    }
   ],
   "source": [
    "#SEPARATE PRODUCTS IN ORDERS (string)\n",
    "\n",
    "\n",
    "# the order_products string equals to a row in df['order']\n",
    "# order_products = \"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\"\n",
    "order_products = \"Large Hot Chocolate - 1.70, Regular Hot Chocolate - 1.40, Large Chai latte - 2.60, Regular Chai latte - 2.30, Regular Speciality Tea - English breakfast - 1.30\"\n",
    "\n",
    "#LOGIC...\n",
    "\n",
    "# A segment (named chuck in the program) is a part of the string delimited by commas (each product in the order a dash and their price)\n",
    "# If a segment has two dashes then the first one will be the product name and the second will be the price\n",
    "# If a segment has three dashes then the first two will be the product name and the third will be the price\n",
    "\n",
    "chunks = order_products.split(',')\n",
    "\n",
    "for dashes in chunks:\n",
    "\n",
    "  if dashes.count('-') == 1:\n",
    "    print(dashes[:dashes.index(\"-\")])\n",
    "    print(f\"Price: \" + dashes.split('-')[1])\n",
    "  else: \n",
    "    stripped = dashes.split('-')[0] + \"-\" + dashes.split('-')[1]  #If the name contains a dash, combine it.\n",
    "    print(stripped)\n",
    "    print(f\"Price: \" + dashes.split('-')[2])\n",
    "\n",
    "\n",
    "# We could use this to easily separate flavors from the drinks as well  they will be in: dashes.split('-')[1] assuming the Tea Types as flavors... #\n",
    "# but that's another table to relate and probably won't be worth the trouble.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product:  Regular Speciality Tea - English breakfast \n",
      "Flavor:  Hazelnut \n",
      "Price:  2.75\n",
      "Product:  Large Latte \n",
      "Price: 2.45\n"
     ]
    }
   ],
   "source": [
    "# SEPARATE \n",
    "\n",
    "#SEPARATE PRODUCTS IN ORDERS WITH FLAVORS (string)\n",
    "\n",
    "\n",
    "# the order_products string equals to a row in df['order']\n",
    "order_products = \"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\"\n",
    "# order_products = \"Large Hot Chocolate - 1.70, Regular Hot Chocolate - 1.40, Large Chai latte - 2.60, Regular Chai latte - 2.30, Regular Speciality Tea - English breakfast - 1.30\"\n",
    "\n",
    "#LOGIC...\n",
    "\n",
    "# A segment (named chuck in the program) is a part of the string delimited by commas (each product in the order a dash and their price)\n",
    "# If a segment has two dashes then the first one will be the product name and the second will be the price\n",
    "# If a segment has three dashes then the first two will be the product name and the third will be the price\n",
    "\n",
    "chunks = order_products.split(',') \n",
    "\n",
    "for dashes in chunks:\n",
    "\n",
    "  if dashes.count('-') == 1:\n",
    "    product = dashes[:dashes.index(\"-\")]  \n",
    "    price = dashes.split('- ')[1]\n",
    "    \n",
    "    print(f\"Product: {product}\")\n",
    "    print(f\"Price: {price}\")\n",
    "    \n",
    "  else: \n",
    "    product = dashes.split('-')[0]\n",
    "    flavor = dashes.split('-')[1]\n",
    "    price = dashes.split('-')[2] \n",
    "    \n",
    "    print(f\"Product: {stripped}\")\n",
    "    print(f\"Flavor: {flavor}\")\n",
    "    print(f\"Price: {price}\")\n",
    " \n",
    "    \n",
    "    # With this one we can have better statistics and also count the number of flavors.\n",
    "    # REMEMBER TO REMOVE THE EMPTY SPACE AFTER THE COMMA... (TYPE(LIST)) FOR PRODUCTS AND PRICE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET NUMBER OF ROWS OF THE DATA FRAME\n",
    "#### We can use any of the following methods to get the number of rows in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET NUMBER OF ROWS OF THE DATA FRAME\n",
    "\n",
    "# len(df.index)\n",
    "# df[df.columns[0]].count()\n",
    "df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if a file exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKS IF A FILE EXIST \n",
    "\n",
    "file_exists = os.path.exists(csv)\n",
    "print(file_exists)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SORTING THE DATE FOR POSTGRE'S [YYYY-MM-DD H:MM:SS] FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SORTING THE DATE FOR POSTGRE'S YYYY-MM-DD H:MM:SS FORMAT\n",
    "\n",
    "# Current Files are Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "\n",
    "def sort_time_to_postgre_format():\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], dayfirst=True)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TEST RUN] SORTING THE DATE FOR POSTGRE'S YYYY-MM-DD H:MM:SS FORMAT\n",
    "\n",
    "# Current Files are Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file)                                                           \n",
    "columns = ['date_time', 'Location', 'full_name', 'order', 'amount', 'payment_type', 'card_number']  # Headers for the DF\n",
    "# df = pd.read_csv(csv, header=None, names=columns)                                                   # Creates the DF\n",
    "\n",
    "sort_time_to_postgre_format()\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pymysql \n",
    "\n",
    "#THIS IS AN EXAMPLE OF THE CONNECT WITH DB CLASS THAT I WAS DOING BEFORE...\n",
    "#CHANGE THE VALUES IN THE TRY STATEMENT TO MAKE IT WORK WITH YOUR LOCAL DB \n",
    "\n",
    "\n",
    "### I did it with pymysql because I don't have a working postgre docker image atm) ... just replace every pymysql in the code for the other import  \n",
    "# that handles postgre... connection methods are indentical.\n",
    "\n",
    "\n",
    "#An Insert would be\n",
    "\n",
    "\n",
    "\n",
    "class WithDB():\n",
    "\n",
    "# SELECT [SQL] (2 arguments, SELECT = \"*\" TABLE = \"table_name\")\n",
    "\n",
    "    def select(select, table):\n",
    "        \n",
    "        try:\n",
    "            print(\"Connecting to DataBase...\")\n",
    "            host_name = \"localhost\"\n",
    "            database_name = \"raw_database\"\n",
    "            user_name = \"root\"\n",
    "            user_password = \"password\"\n",
    "\n",
    "            with pymysql.connect(\n",
    "                        host = host_name,\n",
    "                        database = database_name,\n",
    "                        user = user_name,\n",
    "                        password = user_password\n",
    "                    ) as connection:\n",
    "            \n",
    "                cursor = connection.cursor()\n",
    "                \n",
    "                sql = f\"SELECT {select} FROM {table}\"\n",
    "                cursor.execute(sql)\n",
    "                table_data = cursor.fetchall()\n",
    "                print(table_data)\n",
    "                connection.commit()\n",
    "        \n",
    "        except Exception as ex:\n",
    "            print(\"Failed to open connection, please make sure DB is Running\")\n",
    "            \n",
    "\n",
    "def insert(row, table,columns):\n",
    "        \n",
    "        try:\n",
    "            print(\"Connecting to DataBase...\")\n",
    "            host_name = \"localhost\"\n",
    "            database_name = \"raw_database\"\n",
    "            user_name = \"root\"\n",
    "            user_password = \"password\"\n",
    "\n",
    "            with pymysql.connect(\n",
    "                        host = host_name,\n",
    "                        database = database_name,\n",
    "                        user = user_name,\n",
    "                        password = user_password\n",
    "                    ) as connection:\n",
    "            \n",
    "                cursor = connection.cursor()\n",
    "                \n",
    "                sql = f\"INSERT INTO {table} {columns} VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "                values = columns\n",
    "                \n",
    "                cursor.execute(sql,values)\n",
    "                table_data = cursor.fetchall()\n",
    "                print(table_data)\n",
    "                connection.commit()\n",
    "        \n",
    "        except Exception as ex:\n",
    "            print(\"Failed to open connection, please make sure DB is Running\")\n",
    "    \n",
    "\n",
    "#The whole idea of the \"WithDB\" class is that I can be called like this for different scenarios\n",
    "WithDB.select(\"*\",\"raw_order\")\n",
    "\n",
    "\n",
    "\n",
    "# A row example.... edit for one value if it fails so you can check how it works\n",
    "row = '(25/08/2021 09:00, Chesterfield,Richard Copeland, \"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\", 5.2, CARD, 5494173772652516)'\n",
    "# the target table \n",
    "table = \"raw_order\"\n",
    "#your table db columns  \n",
    "columns = '(raw_id,date,location,full_name,orders,transaction_total,payment_type,card_number)'\n",
    "\n",
    "#then you can call it like this:\n",
    "WithDB.insert(row,table,columns)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PIPELINE ROUTE...\n",
    "\n",
    "### 1. READ CSV FILE AS DATA FRAME\n",
    "\n",
    "EXAMPLE OF A ROW AT THIS POINT: <br>\n",
    "25/08/2021 09:00, Chesterfield,Richard Copeland, \"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\", 5.2, CARD, 5494173772652516\n",
    "\n",
    "### 2. REMOVE THE COLUMNS NAME, CARD NUMBER\n",
    "\n",
    "EXAMPLE OF A ROW AT THIS POINT:  <br>\n",
    "25/08/2021 09:00, Chesterfield, \"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\", 5.2, CARD\n",
    "\n",
    "\n",
    "### 3. CHANGE DATE FORMAT TO POSTQGRE'S FORMAT\n",
    "\n",
    "EXAMPLE OF A ROW AT THIS POINT:  <br>\n",
    "\n",
    "2021/08/25 09:00, Chesterfield,\"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\", 5.2, CARD\n",
    "\n",
    "\n",
    "### 4. NORMALISE LOCATION AND PAYMENT_TYPE (A FUNCTION THAT CONNECTS TO DB AND CHECK IF THE LOCATION EXISTS RETURNING THE ID, IF NOT ADDS IT SHOULD BE CREATED)\n",
    "\n",
    "EXAMPLE OF A ROW AT THIS POINT:  <br>\n",
    "\n",
    "2021/08/25 09:00, 1 ,\"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\", 5.2, 2\n",
    "\n",
    "\n",
    "### 5. EXTRACT PRODUCTS FROM EACH ORDER AND ADD THEM TO A SEPARATE DATA FRAME WITH [ORDER_ID] [PRODUCT_NAME]\n",
    "\n",
    "EXAMPLE OF A ROW AT THIS POINT: <br>\n",
    "\n",
    "2021/08/25 09:00, 1 ,1, 5.2, 2  <br>\n",
    "\n",
    "AND THIS WILL BE THE ORDER FOR SAID ROW  <br>\n",
    "\n",
    "Regular Flavoured iced latte - Hazelnut - 2.75\n",
    "Large Latte - 2.45\"\n",
    "\n",
    "\n",
    "### 6. NORMALISE ORDER PRODUCTS (A FUNCTION THAT CONNECTS TO DB AND CHECK IF THE LOCATION EXISTS RETURNING THE ID, IF NOT ADDS IT SHOULD BE CREATED)\n",
    "\n",
    "EXAMPLE OF A ROW AT THIS POINT: <br>\n",
    "\n",
    "2021/08/25 09:00, 1 ,1, 5.2, 2 <br>\n",
    "\n",
    "AND THIS WILL BE THE ORDER FOR SAID ROW <br>\n",
    "\n",
    "1,1\n",
    "1,2\n",
    "\n",
    "\n",
    "### 7. INSERT THOSE TWO DF'S TO THE DB\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
