{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Variables used for testing\n",
    "import pandas as pd                                                                                 # Loads Pandas package\n",
    "import json                                                                                         # Loads JSON package \n",
    "import os                                                                                           # For OS related paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ABSOLUTE PATH FOR RAW DATA   \n",
    "\n",
    "# takes: raw_data_name that should be the name of one of the csv's files \n",
    "# returns: absolute path to the raw_data subfolder folder plus raw_data_name AS a variable named csv \n",
    "\n",
    "\n",
    "def absolute_path_for_raw_data(raw_data_file):\n",
    "    abspath = os.path.abspath(\"../raw_data\")\n",
    "    global csv\n",
    "    csv = abspath + \"\\\\\" + raw_data_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. [TEST RUN] ABSOLUTE PATH FOR RAW DATA\n",
    "\n",
    "# Current Files are Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file)\n",
    "print(csv) # Prints the newly formed absolute path with the raw_data_file name given.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. EXTRACT SANITISE CSV (Remove given Columns) \n",
    "\n",
    "# takes: csv(absolute path to filename), and a list of columns to be dropped on a variable called sanatise_these_columns\n",
    "# returns: the sanitised dataframe as df\n",
    "\n",
    "def extract_sanitise_csv(csv,sanitise_these_columns):\n",
    "    try:\n",
    "        global df # as Global to be able to print it outside the function\n",
    "        df = pd.read_csv(csv, header=None, names=columns)\n",
    "        df = df.drop(columns=sanitise_these_columns)\n",
    "    except FileNotFoundError as fnfe:\n",
    "        print(f'File not found: {fnfe}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. [TEST RUN] EXTRACT SANITISE CSV \n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "columns = ['date_time', 'Location', 'full_name', 'order', 'amount', 'payment_type', 'card_number']  # Headers for the orders csv files\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file)  # returns csv variable with the absolute path\n",
    " \n",
    "sanitise_these_columns = ['full_name', 'card_number']\n",
    "\n",
    "extract_sanitise_csv(csv,sanitise_these_columns)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FILTER BY COLUMN VALUE \n",
    "\n",
    "# Takes: csv(absolute path to filename), column variable with the column header id, value to check\n",
    "# Returns: the rows in which a column contains a given value AS contain_values\n",
    "\n",
    "def filter_by_column_value(csv,column,value):\n",
    "    try:\n",
    "        global contain_values # as Global to be able to print it outside the function\n",
    "        contain_values = df[df[column].str.contains(value.upper())]\n",
    "    except FileNotFoundError as fnfe:\n",
    "        print(f'File not found: {fnfe}')\n",
    "\n",
    "    return contain_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. [TEST RUN] FILTER BY COLUMN VALUE\n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "# raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "column = \"payment_type\"  \n",
    "value = \"card\"\n",
    "\n",
    "filter_by_column_value(csv,column,value)\n",
    "contain_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. COUNT NUMBER OF DIFFERENT VALUES IN COLUMN \n",
    "\n",
    "# Takes: csv(absolute path to filename), column variable with the column header id,\n",
    "# Returns: the count of the different values contained in a given column\n",
    "\n",
    "def count_number_of_different_values(csv,column):\n",
    "    try:\n",
    "        global count  # as Global to be able to print it outside the function\n",
    "        count = df[column].value_counts(ascending=True)\n",
    "    except FileNotFoundError as fnfe:\n",
    "         print(f'File not found: {fnfe}')\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. [TEST RUN] COUNT NUMBER OF DIFFERENT VALUES IN COLUMN \n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file) # returns csv variable with the absolut path\n",
    "\n",
    "column = \"payment_type\" \n",
    "\n",
    "count_number_of_different_values(csv,column)\n",
    "print(str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. COUNT NUMBER OF TIMES A VALUE IS REPEATED\n",
    "# \n",
    "# Takes: csv(absolute path to filename), column variable with the column header id, value to check\n",
    "# Retuns: the count of the number of times a single value is repeated on a given column AS count\n",
    "\n",
    "def count_number_of_times_a_value_is_repeated(csv,column,value):\n",
    "    try:\n",
    "        df = pd.read_csv(csv, header=None, names=columns)\n",
    "        global count # as Global to be able to print it outside the function\n",
    "        count = df[column].value_counts()[value]\n",
    "    except FileNotFoundError as fnfe:\n",
    "         print(f'File not found: {fnfe}')\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. [TEST RUN] COUNT NUMBER OF TIMES A VALUE IS REPEATED\n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file) # returns csv variable with the absolut path\n",
    "\n",
    "column = \"payment_type\"\n",
    "value = \"CARD\" \n",
    "\n",
    "count_number_of_times_a_value_is_repeated(csv,column,value)\n",
    "print(\"the value: \" + value + \" was found \" + str(count) + \" times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. SAVE DATA FRAME TO FILE AS CSV\n",
    "\n",
    "# Takes: path for the desired save path, newfile for the desired new file name (.csv extension added at runtime)\n",
    "# Retuns: a csv file saved to the desired location that contains the DF\n",
    "\n",
    "def save_df_to_csv(path,newfile):\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)  \n",
    "        df.to_csv(path + newfile +\".csv\", header=False)\n",
    "\n",
    "    except:\n",
    "        print(f'Saving operation could not be completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. [TEST RUN] SAVE DATA FRAME TO FILE AS CSV\n",
    "path = \"results/\" # to add folder/subfolder/ if needed\n",
    "newfile = \"newfile\"\n",
    "\n",
    "save_df_to_csv(path,newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. SAVE DATAFRAME TO FILE AS JSON\n",
    "\n",
    "# Takes: path for the desired save path, newfile for the desired new file name (.json extension added at runtime)\n",
    "# Retuns: a csv file saved to the desired location that contains the DF\n",
    "\n",
    "def save_df_to_json(path,newfile):\n",
    "    try:\n",
    "        with open(path + newfile +\".json\", 'w') as f:\n",
    "            f.write(df.to_json(orient='records', lines=True))  # add compression='gzip' to get a zip file (and change newfile extension)\n",
    "\n",
    "    except:\n",
    "        print(f'Saving operation could not be completed')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. [TEST RUN] SAVE DATAFRAME TO FILE AS JSON\n",
    "\n",
    "path = \"results/\" # to add folder/subfolder/ if needed\n",
    "newfile = \"newfile\"\n",
    "\n",
    "save_df_to_json(path,newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GET UNIQUE PRODUCTS IN ORDERS\n",
    "# Returns a list with the number of  ocurrences for each product\n",
    "\n",
    "\n",
    "def get_unique_products_in_orders():\n",
    "    # df = pd.read_csv(csv, header=None, names=columns)  # Not needed if you're coming from another function that already read this\n",
    "    orders = df['order'].str.split(',', expand = True)\n",
    "        \n",
    "    for item in orders:\n",
    "        global result\n",
    "        result = orders[item].drop_duplicates()\n",
    "\n",
    "    return result \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TEST RUN] GET UNIQUE PRODUCTS IN ORDERS\n",
    "\n",
    "\n",
    "# Current Files Chesterfield or Leeds (comment one out)\n",
    "# raw_data_file = \"chesterfield_25-08-2021_09-00-00.csv\"\n",
    "raw_data_file = \"leeds_01-01-2020_09-00-00.csv\"\n",
    "\n",
    "absolute_path_for_raw_data(raw_data_file) # returns csv variable with the absolut path\n",
    "result = \"\"\n",
    "\n",
    "\n",
    "get_unique_products_in_orders()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARATE PRODUCTS IN ORDERS (string)\n",
    "\n",
    "\n",
    "# the order_products string equals to a row in df['order']\n",
    "# order_products = \"Regular Flavoured iced latte - Hazelnut - 2.75, Large Latte - 2.45\"\n",
    "order_products = \"Large Hot Chocolate - 1.70, Regular Hot Chocolate - 1.40, Large Chai latte - 2.60, Regular Chai latte - 2.30, Regular Speciality Tea - English breakfast - 1.30\"\n",
    "\n",
    "#LOGIC...\n",
    "\n",
    "# A segment (named chuck in the program) is a part of the string delimited by commas (each product in the order with their price)\n",
    "# If a segment has two dashes then the first one will be the product name and the second will be the price\n",
    "# If a segment has three dashes then the first two will be the product name and the third will be the price\n",
    "\n",
    "chunks = order_products.split(',')\n",
    "\n",
    "for dashes in chunks:\n",
    "\n",
    "  if dashes.count('-') == 1:\n",
    "    print(dashes[:dashes.index(\"-\")])\n",
    "    print(f\"Price: \" + dashes.split('-')[1])\n",
    "  else: \n",
    "    stripped = dashes.split('-')[0] + \"-\" + dashes.split('-')[1]  #If the name contains a dash, combine it.\n",
    "    print(stripped)\n",
    "    print(f\"Price: \" + dashes.split('-')[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET NUMBER OF ROWS OF THE DATA FRAME\n",
    "# We can use any of the following methods to get the number of rows in a data frame\n",
    "\n",
    "# len(df.index)\n",
    "# df[df.columns[0]].count()\n",
    "df.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
